{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! / usr / bin / env python\n",
    "coding: utf - 8\n",
    "\n",
    "\"\"\"RadCLIP GPT-2 Model\"\"\"\n",
    "\n",
    "__author__ = \"Christoper Alexander\"\n",
    "__copyright__ = \"Copyright 2023\"\n",
    "__credits__ = [\"Andrew D'Amico\", \"Christoper Alexander\", \"Katya Nosulko\", \"Vivek Chamala\", \"Matthew Conger\"]\n",
    "__license__ = \"\"\n",
    "__version__ = \"0.0.1\"\n",
    "__maintainer__ = \"Andrew Damico\"\n",
    "__email__ = \"andrew.damico@u.northwestern.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3448754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/transformers/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, GPT2Config,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcfb8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    'gpt2-xl', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b61a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = GPT2Config.from_pretrained('gpt2-xl', output_hidden_states=False)\n",
    "configuration.pad_token_id = configuration.eos_token_id\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\", config=configuration, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4755b2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 1600)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acd5fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-73b982222f046e78/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n",
      "100%|██████████| 2/2 [00:00<00:00, 825.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"text\", data_files={\"train\": \"train_gpt.txt\", \"test\": \"test_gpt.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111095e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-73b982222f046e78/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-096307c9d53f8711.arrow\n",
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    lambda examples: tokenizer(examples[\"text\"], max_length=1024, truncation=True, padding=\"max_length\"), batched=True\n",
    ")\n",
    "test_dataset = dataset[\"test\"].map(\n",
    "    lambda examples: tokenizer(examples[\"text\"], max_length=1024, truncation=True, padding=\"max_length\"), batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7128db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fae9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"test_gpt_xl_10k\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_steps=1000,\n",
    "    save_steps=2000,\n",
    "    warmup_steps=100,\n",
    "    # prediction_loss_only=True,\n",
    "    logging_dir=\"logs_gpt_xl\",\n",
    "    logging_steps=50,\n",
    "    # fp16=True, # Enable mixed precision training\n",
    "    # half_precision_backend=\"auto\", # Set the backend for mixed precision training\n",
    "    ddp_find_unused_parameters=None,\n",
    "    optim=\"adamw_torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac659aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d324f3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506a5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gptxl_10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bb48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01b3d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generator(\n",
    "    \"This is the condition: there is no pneumothorax or pleural effusion. Explanation:\",\n",
    "    max_length=300,\n",
    "    num_return_sequences=2,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68217881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the condition: there is no pneumothorax or pleural effusion. Explanation: the patient suffered from some kind of atypical virus pneumonia, but no atypical pneumonia was involved. Clinical manifestation: This patient had obvious clinical manifestations of pneumonia, so chest X-ray examination was necessary and performed to verify the presence of pneumothorax and pleural effusion. In this examination, there was obviously increased absorption in the bilateral lungs and severe pneumonia in the bilateral pulmonary lobes. In addition, there were obvious changes in the color of the pleural effusion and decreased absorption in the bilateral lungs (Fig. ). The diagnostic criteria for viral pneumonia are as follows: The treatment methods for respiratory illness of children includes oxygen inhalation, simple aspiration, sputum suction and medication. However, it is necessary to conduct aggressive treatment immediately after the onset of respiratory illness. At present, there are few clinical studies on the diagnosis and treatment of pneumonia in children. In clinical practice, chest X-ray examination is used to detect pneumothorax in patients with pulmonary embolism. However, the diagnostic criteria for chest X-ray examination to detect pneumothorax in patients with pulmonary embolism have not been clarified. Pulmonary embolism and pneumothorax have been confirmed by chest computed tomography in patients with acute pulmonary embolism. This examination shows that the number of pulmonary emboli in the lungs increases and pulmonary nodules or masses\n"
     ]
    }
   ],
   "source": [
    "print(test[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27030def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the condition: there is no pneumothorax or pleural effusion. Explanation: in the process of healing, the pressure just entered the chest cavity. The lung was injured at the middle of the fourth intercostal space, the pleural cavity was filled with fluid. During the chest wall healing, the visceral pleura were retracted, and the parietal pleura were stretched to prevent the lung from expanding. As the chest wall was normal, the patient didn't have enough lung. There was a small amount of pleural fluid in the thoracic cavity, and the blood pressure in the thoracic cavity was not enough to relieve the pressure of the diaphragm and heart. The patient did not tolerate the discomfort caused by radiation and chemotherapy. On May 26, 2020, the patient died. Histopathologically, the tumor cells showed a pattern of pleural and intrapleural growth, which was not observed in the first stage. By May 26, the lung tissue became more dense, solid, and hollow. The second phase of the tumor was marked by extensive hemorrhage, necrosis, fibrous tissue formation, and connective tissue degeneration (Figures and ). Tumor cells invaded through the thin fibrous pleura to form subpleural solid masses and tumors with internal hemorrhage. At the same time, the lymphatic vessels in the blood vessels were dilated with destruction of normal parenchyma and tumor tissue, which formed dense\n"
     ]
    }
   ],
   "source": [
    "print(test[1][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f113708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gptxl_10k/tokenizer_config.json',\n",
       " 'gptxl_10k/special_tokens_map.json',\n",
       " 'gptxl_10k/vocab.json',\n",
       " 'gptxl_10k/merges.txt',\n",
       " 'gptxl_10k/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"gptxl_10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad614d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
